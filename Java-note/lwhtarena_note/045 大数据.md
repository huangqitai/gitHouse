# 大数据

## 企业中大数据常用的技术框架
+ 1、Hadoop		大数据基石
+ 2、Hive		数据仓库 ETL相关
+ 3、HBase		数据仓库 ETL相关
+ 4、Zookeeper	大数据调度框架
+ 5、Spark		 大数据内存计算框架
+ 6、Storm 		大数据实时计算框架
+ 7、impala		基于Hive的内存查询
+ 8、kafka		消息中间件
+ 9、Redis 		常用存储NoSql
+ 10、SQL知识	 增删改查
+ 11、Flink		新一代计算引擎
+ 12、oozie		调度框架
+ 13、mysql、oracle  传统数据库

> 前置知识

+ Linux 系统，基本命令
```
`[root@hadoop-senior Desktop] #`  
用户名		主机名	 所在目录名称

 有两个字符   
   + `#` ：表示当前用户属于root用户，超级管理员用户   
       对系统进行配置管理的时候，需要使用root用户   
   + `$` : 表示用户属于普通用户
   清理屏幕
	# clear
创建用户
	# useradd beifeng
	对于Linux下每个用户，都有密码
	# passwd beifeng
	在Linux系统下，默认情况下，创建一个用户的同时会给用户在系统的目录下创建一个属于自己的用户目录，改目录称为用户主目录
	规则：/home/username
	beifeng用户：/home/beifeng, 用户主目录可以使用 ~ 进行表示
切换用户
	#|$ su - beifeng
	注意事项：
		* root用户切换到普通用户
			# su - beifeng
			不需要输入密码
		* 普通用户切换到root用户
			$ su
			需要输入root用户秘密
显示当前用户所在的目录
	$|# pwd
Linux系统的主机名称
	* 查看主机名称
		#|$ hostname
	* 设置主机名称
		# hostname hadoop-senior.ibeifeng.com
	注意事项：
		此种方式设置主机名称，仅仅在当前使用没有问题，当时重启机器以后，主机名称会变化。
		为什么？？？？？
		原因：在linux系统中，系统的配置的信息都是来自于文件中。
	* 永久性的设置主机名称
		# cat /etc/sysconfig/network

读取linux系统上文件内容的命令
	cat

Linux编辑工具VI
	# vi filename    -- 编辑文件内容
	进入编辑插入模式
		i
	推出插入模式
		Esc
	保持文件
		第一步：冒号（:）
		第二步：wq
	不保存文件
		第一步：冒号（:）
		第二步：q!

重启系统
	* 关机
		# halt
	* 重启
		# reboot
		# init 6

主机名与IP地址映射
	hadoop-senior.ibeifeng.com
	192.168.217.110
	配置文件
		/etc/hosts
	192.168.217.110	 hadoop-senior.ibeifeng.com  hadoop-senior
Win7系统
	C:\Windows\System32\drivers\etc\hosts
	192.168.217.110	 hadoop-senior.ibeifeng.com  hadoop-senior
主机名称与IP地址映射配置的好处，作用非常大。

当前目录下，有哪些文件
	ls   -- list
	ls -l
	ll
	ls -a
		比ls 多了一些以.开头的文件，以.开头的文件，隐藏文件

特殊目录标识符
	* 一个点 `.` ：  表示的是当前目录
	* 两个点 `..` :	表示的是上级（父级）目录

切换目录
	cd dirName
	change directory

创建一个文件
	touch readme.txt

    
>>>>>>用户和组
	Linux系统上，创建用户的时候，默认情况会给我们创建一个用户组（名称与用户名相同）

>>>>>>>> 文件
在Linux系统下面，文件类型（常见三种类型）
	* 文件
		-
	* 目录（类似Win7下的文件夹）
		d
	* 连接（类似Win7下快捷方式）
		l
文件权限
	* 可读 r
	* 可写 w
	* 可执行（脚本，比如shell脚本） x
	特殊字符
		-
		表示的是没有任何权限
权限数字表示方法
	rw-  ->  6
	二进制数字之和的方式
	R 		W 		X
	2^2     2^1 	2^0
	4 		2 		1


文件的归属
	* 拥有者 owner  u
	* 属于组 group  g
	* 其他人 other  o

----------------------------------------------------
drwxr-xr-x. 2 beifeng beifeng      4096 Sep 28 11:05 Downloads

-rw-rw-r--. 1 beifeng beifeng        65 Sep 28 12:15 hive-select-log.sql


第一部分：
	-rw-rw-r--
十个字符，代表不同的意义
	-	rw- 	rw- 	r--   -> 数字表示权限:   664
第一字符：
	表示的是文件的类型
后面的九个字符，分为三组，表示此文件针对不同用户的权限关系。
	为什么是三组？
	因为一个文件对于用户来说，三个部分
		* 拥有者 rw-   
		* 所属组 rw-
		* 其他人 r--
第二部分：
	beifeng beifeng
* 第一字符串表示的是 文件的拥有者 ，beifeng
* 第二个字符表示的是 文件所属组， beifeng

* man cmdName
* 命令行来说，自动补全功能，Tab键

如何设置文件对不同用户的权限
	需要使用root用户
chmod 命令
	change mode
eg：
	-rw-rw-r--. 1 beifeng beifeng        65 Sep 28 12:32 hive-select-log.sql
需求：
	对于同组用户来说，仅仅可读；对于其他用户来说，既不可读也不可写。
	# chmod g-w hive-select-log.sql
	# chmod o-r hive-select-log.sql
数字形式
	# chmod 664 hive-select-log.sql
问题:
	如果针对一个目录，设置权限呢？？ 目录中有很多文件，也需要同样的权限设置
-R, --recursive     递归
              change files and directories recursively
    # chmod -R 664 /opt/softwares

>>>>>>>> 文件拷贝
$ cp hive-select-log.sql /home

>>>>>>>> 改变文件拥有者和所属组
命令
	chowner
		# chown beifeng /home/hive-select-log.sql
	chgrp
		# chgrp beifeng /home/hive-select-log.sql
如果针对目录
		# chown -R beifeng /opt/softwares
案例：
	将/home/hive-select-log.sql 拥有者和所属组设置为senior用户和senior组
可以使用一条命令完成操作
	# chown senior:senior /home/hive-select-log.sql

>>>>> 文件创建
* 使用touch命令
	$ touch test.data
* 使用vi/vim方式
	$ vi test.txt

对文件的内容进行追加
	$ echo "xxxxyyyyzzz" >> text.txt

编辑文件内容vi/vim
	快捷键
	在vi查看模式下
		* dd ：表示删除光标所在的行的内容
		* ZZ ：表示的是保存文件内容
		* x  ：表示将光标处的字符给删除
		* o  : 表示在光标的下一行进行插入内容

查看文件内容的常见几种方式
	* cat  ： 全部内容,内容比较少
	* more :  翻页查看
	* tail :  末尾内容，通常与 -f参数连用，适合于查看服务实时动态日志信息
		eg:
			tail -f xxxx.log
			tail -200f yyy.log
	* head :  开头文件，文件格式，内容模板样式
>>>>>> 文件拷贝，移动，重命名
拷贝
		语法：cp source dest
		dest:
			文件名称，可以是目录
		## 拷贝一个文件到一个目录中去
		$ cp test.txt test-dir
		## 拷贝一个文件的内容至一个文件中（新文件）
		$ cp test.txt cp-test.txt
	source
		拷贝一个目录
		$ cp -r test-dir test-dir2
移动或者重命名
	语法：
		mv src dest
	重命名
		src和dest在同一个目录下
	$ mv test-dir/ sub-dir
	$ mv test.txt test.log
	移动
		src和dest不在同一目录或者
	$ mv test-dir2/sub-dir/ test-dir

>>>>>>>>>>>>文件的删除
$ rmdir test-dir
rmdir 注意删除的目录必须要是空目录
$ rm -rf src
使用的时候：src最好是绝对路劲，确定好以后再删除

>>>>>>>> 创建目录
	$ mkdir test
创建多级目录
	$ mkdir -p ~/data/dfs/tmp

>>>>>>>>>>>>>>>>>>>>>>>>>>
连接 （	类似Win7 快捷方式）
	* 软连接soft link
	* 硬链接hard link
区别：
	在删除连接时，是否删除源文件
案例：
	## 创建一个软连接
	$ ln -s file/dir linkName
	eg:
		$ ln -s readme.txt rm.txt
lrwxrwxrwx. 1 beifeng beifeng       10 Sep 28 16:14 rm.txt -> readme.txt
	## 创建一个硬链接
	$ ln www.ibeifeng.access.log bf-log
就相当于拷贝一个文件了

使用场景：
	/opt/hadoop/conf				/opt/hbase/conf
	core-site.xml					ln -> core-site.xml
	hdfs-site.xml					ln -> hdfs-site.xml
保证一致性

文件搜索
	$ find ~/ -name file
	$ find ~/ -name read\*

>>>>>>系统信息
[beifeng@hadoop-senior ~]$ uname
[beifeng@hadoop-senior ~]$ uname -r
[beifeng@hadoop-senior ~]$ cat /proc/cpuinfo 
[beifeng@hadoop-senior ~]$ cat /proc/meminfo

显示当前系统日期时间
[beifeng@hadoop-senior ~]$ date
Mon Sep 28 16:26:03 EDT 2015
##  显示日历表
[beifeng@hadoop-senior ~]$ cal 2015
## 设置日期和时间
[root@hadoop-senior beifeng]# date -s 2015-09-30
Wed Sep 30 00:00:00 EDT 2015
[root@hadoop-senior beifeng]# date -s 14:42:45
Wed Sep 30 14:42:45 EDT 2015

如何设置普通用户的sudo权限
$ su 
# vi /etc/sudoers
	在第一行添加如下内容：
	beifeng ALL=(root)NOPASSWD:ALL

### 查看防火墙是否关闭
$ sudo service iptables status
### 关闭防火墙
$ sudo service iptables stop
### 启动防火墙
$ sudo service iptables start

永久性设置防火墙关闭
$ sudo chkconfig iptables off|on

SELINUX 禁用
[beifeng@hadoop-senior ~]$ cat /etc/sysconfig/selinux 

# This file controls the state of SELinux on the system.
# SELINUX= can take one of these three values:
#     enforcing - SELinux security policy is enforced.
#     permissive - SELinux prints warnings instead of enforcing.
#     disabled - No SELinux policy is loaded.
SELINUX=enforcing
# SELINUXTYPE= can take one of these two values:
#     targeted - Targeted processes are protected,
#     mls - Multi Level Security protection.
SELINUXTYPE=targeted 

在Linux当中，自带的调度功能crontab
针对用户
	每个用户都可以调度自己的任务

在beifeng用户下创建定时任务
	功能：每分钟执行一次，将时间写入到指定文件中
[beifeng@hadoop-senior ~]$ crontab -e 
### first crobtab
*/1 * * * * /bin/date >> /home/beifeng/bf-log.txt

列出目前所有的定时任务
[beifeng@hadoop-senior ~]$ crontab -l 
### first crobtab
*/1 * * * * /bin/date >> /home/beifeng/bf-log.txt

删除所有的定时任务
[beifeng@hadoop-senior ~]$ crontab -r

>>>>>>>>>>>>>>>>>>>>>>>
crontab 基本定义
语法：
	* * * * * command
说明：
	1）六个字段之间，使用逗号隔开
	2）字段的含义
	*       *        *        *        *
	分：1-59, 每十分钟 */10
			时：0-23,*/2
					日：1 -31
							月：1-12
									   星期：（0-6）

举一些例子：
### 每天21:30 执行
30 21 * * * cmd01

### 每个月1,11,21 的2:30执行
30 2 1,11,21 * * cmd02

### 每周六或者每周日，1:45 执行
45 1 * * 6,0 cmd03

### 每天20：00至 23:00 ，每半个小时执行一次
0,30 20-23 * * * cmd04

### 每一小时执行一次
* */1 * * cmd05
 ```


+ Java 语言，JSE 相关知识
+ mysql 基本DML和 DDL


## Hadoop 

**Hadoop** 是一个由Apache基金会所开发的<font color=#17D9FF size=4>分布式系统</font>基础架构。 实现了一个分布式文件系统（**Hadoop Distributed File System**），简称<font color=#17D9FF size=4>HDFS</font>。

Hadoop的框架最核心的设计就是：<font color=#17D9FF size=4>HDFS</font>和<font color=#17D9FF size=4>MapReduce</font>。HDFS为海量的数据提供了**存储**，则MapReduce为海量的数据提供了**计算**。
